{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcc9d7aa",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "Emma McCready\\\n",
    "sba23001\n",
    "\n",
    "---\n",
    "\n",
    "This dashboard was designed in a separate notebook to the Machine Learning Analysis (found in Codebook 2), as I don't currently have access to the PC I did the original ML analysis on, and I don't want to run or edit the codebook as I'm using a mac, and so the results will be different from when I analysed the results. Therefore, this output of this dashboard will differ from the results in Codebook 2.\n",
    "\n",
    "The code from the best performing ML model (Random Forest Regression) was copied and pasted into this Codebook.\n",
    "\n",
    "---\n",
    "\n",
    "References:\n",
    "\n",
    "[Article: Build a Machine Learning simulation tool with Dash](https://towardsdatascience.com/build-a-machine-learning-simulation-tool-with-dash-b3f6fd512ad6?gi=b773c179715f)  \n",
    "[Article: Deploy Machine Learning Model Using Python Dash and Pipenv](https://towardsdatascience.com/deploy-machine-learning-model-using-dash-and-pipenv-c543569c33a6)  \n",
    "[Article: The quickest way to build Dashboards for Machine Learning models](https://towardsdatascience.com/the-quickest-way-to-build-dashboards-for-machine-learning-models-ec769825070d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88440781",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#!pip install dash\n",
    "#!pip install dash_daq\n",
    "#!pip upgrade explainerdashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d659bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "### ML Libraries:\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import (GridSearchCV, cross_val_score, cross_val_predict, \n",
    "                                     StratifiedKFold, learning_curve, train_test_split)\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.metrics import (r2_score, mean_squared_error, mean_absolute_error,explained_variance_score, \n",
    "                             classification_report, confusion_matrix)\n",
    "from statsmodels.tools.eval_measures import mse, rmse\n",
    "\n",
    "### For Dashboard:\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "import dash_daq as daq\n",
    "from dash.dependencies import Input, Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7698f695",
   "metadata": {},
   "source": [
    "#### First I will import my dataset. \n",
    "The exact same code has been copied from Codebook 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f071ee07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded file: EUROSTAT_Average rating of satisfaction by domain, sex, age and educational attainment level_TIMSAT.csv\n",
      "Loaded file: EUROSTAT_Average rating of satisfaction by domain, sex, age and educational attainment level_LIVENVSAT.csv\n",
      "Loaded file: EUROSTAT_Average rating of satisfaction by domain, sex, age and educational attainment level_RELSAT.csv\n",
      "Loaded file: EUROSTAT_railwaylength.csv\n",
      "Loaded file: EUROSTAT_Nights spent at tourist accommodation establishments.csv\n",
      "Loaded file: EUROSTAT_Average rating of satisfaction by domain, sex, age and educational attainment level_JOBSAT.csv\n",
      "Loaded file: EUROSTAT_Average rating of satisfaction by domain, sex, age and educational attainment level_COMSAT.csv\n",
      "Loaded file: EUROSTAT_Average rating of satisfaction by domain, sex, age and educational attainment level_ACCSAT.csv\n",
      "Loaded file: EUROSTAT_passengers transported_Total.csv\n",
      "Loaded file: EUROSTAT_Passenger train traffic performance by type of train speed.csv\n",
      "Loaded file: EUROSTAT_At-risk-of-poverty rate by poverty threshold, age and sex_EU-SILC and ECHP surveys.csv\n",
      "Loaded file: EUROSTAT_Average rating of satisfaction by domain, sex, age and educational attainment level_GREENSAT.csv\n",
      "Loaded file: EUROSTAT_Average rating of satisfaction by domain, sex, age and educational attainment level_LIFESAT.csv\n",
      "Loaded file: EUROSTAT_Average rating of satisfaction by domain, sex, age and educational attainment level_MEANLIFE.csv\n",
      "Loaded file: EUROSTAT_passengers transported_PKM.csv\n",
      "Loaded file: EUROSTAT_Average rating of satisfaction by domain, sex, age and educational attainment level_FINSAT.csv\n",
      "Loaded file: EUROSTAT_Railway accidents by type of accident.csv\n"
     ]
    }
   ],
   "source": [
    "files = glob.glob('EUROSTAT*.csv')\n",
    "EUROSTAT_data = pd.DataFrame()  # to store merged data\n",
    "loaded_files = []  # so the list of files loaded in can be seen in the correct order\n",
    "\n",
    "for i, f in enumerate(files):\n",
    "    dataset = pd.read_csv(f) \n",
    "    \n",
    "    obs_columns = [col for col in dataset.columns if col.startswith('OBS_VALUE')]\n",
    "    dataflow_value = dataset['DATAFLOW'].iloc[0]  # i used 0 just because it's constant in the dataset anyway\n",
    "    rename_mapping = {obs_column: f'{dataflow_value}_{obs_column.split(\"_\")[-1]}' for obs_column in obs_columns} # so that the output will be \"[survey code]_VALUE\"\n",
    "    dataset.rename(columns=rename_mapping, inplace=True)\n",
    "    \n",
    "    unit_columns = [col for col in dataset.columns if col.startswith('unit')]\n",
    "    rename_mapping_unit = {unit_column: f'{dataflow_value}_{unit_column.split(\"_\")[-1]}' for unit_column in unit_columns} \n",
    "    dataset.rename(columns=rename_mapping_unit, inplace=True)\n",
    "    \n",
    "    filter_cols = ['accident', 'isced11', 'c_resid'] \n",
    "    for col in filter_cols:\n",
    "        if col in dataset.columns:\n",
    "            dataset = dataset[dataset[col] == 'TOTAL'] # to keep just the total values\n",
    "\n",
    "    loaded_files.append(f)\n",
    "    print(f'Loaded file: {f}')\n",
    "\n",
    "    if EUROSTAT_data.empty:\n",
    "        EUROSTAT_data = dataset\n",
    "    else:\n",
    "        suffixes = ('', f'_{i}')  # to solve merge error issue\n",
    "        EUROSTAT_data = pd.merge(EUROSTAT_data, dataset, on=['geo', 'TIME_PERIOD'], how='outer', suffixes=suffixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e453d1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 953 entries, 0 to 952\n",
      "Data columns (total 19 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   geo               953 non-null    object \n",
      " 1   TIME_PERIOD       953 non-null    int64  \n",
      " 2   ILC_PW01          54 non-null     float64\n",
      " 3   ILC_PW01_1        27 non-null     float64\n",
      " 4   ILC_PW01_2        54 non-null     float64\n",
      " 5   TTR00003          300 non-null    float64\n",
      " 6   TOUR_OCC_NINATS   295 non-null    float64\n",
      " 7   ILC_PW01_5        54 non-null     float64\n",
      " 8   ILC_PW01_6        27 non-null     float64\n",
      " 9   ILC_PW01_7        27 non-null     float64\n",
      " 10  RAIL_PA_TOTAL     431 non-null    float64\n",
      " 11  RAIL_TF_PASSMOV   783 non-null    float64\n",
      " 12  ILC_LI02          615 non-null    float64\n",
      " 13  ILC_PW01_11       27 non-null     float64\n",
      " 14  ILC_PW01_12       108 non-null    float64\n",
      " 15  ILC_PW01_13       27 non-null     float64\n",
      " 16  RAIL_PA_TOTAL_14  430 non-null    float64\n",
      " 17  ILC_PW01_15       54 non-null     float64\n",
      " 18  RAIL_AC_CATNMBR   300 non-null    float64\n",
      "dtypes: float64(17), int64(1), object(1)\n",
      "memory usage: 141.6+ KB\n"
     ]
    }
   ],
   "source": [
    "columns_to_drop = EUROSTAT_data.columns[EUROSTAT_data.columns.str.startswith('DATAFLOW') | \n",
    "                                        EUROSTAT_data.columns.str.startswith('LAST') | \n",
    "                                        EUROSTAT_data.columns.str.startswith('freq') |\n",
    "                                        EUROSTAT_data.columns.str.startswith('OBS_FLAG') | \n",
    "                                        EUROSTAT_data.columns.str.startswith('sex') |\n",
    "                                        EUROSTAT_data.columns.str.startswith('age') |\n",
    "                                        EUROSTAT_data.columns.str.startswith('indic_il') |\n",
    "                                        EUROSTAT_data.columns.str.startswith('nace_r2') |\n",
    "                                        EUROSTAT_data.columns.str.startswith('vehicle') |\n",
    "                                        EUROSTAT_data.columns.str.startswith('tra_infr') |\n",
    "                                        EUROSTAT_data.columns.str.startswith('n_tracks') |\n",
    "                                        EUROSTAT_data.columns.str.startswith('indic_wb') |\n",
    "                                        EUROSTAT_data.columns.str.startswith('isced11') |\n",
    "                                        EUROSTAT_data.columns.str.startswith('accident') |\n",
    "                                        EUROSTAT_data.columns.str.startswith('VALUE') |\n",
    "                                        EUROSTAT_data.columns.str.startswith('c_resid') |\n",
    "                                        EUROSTAT_data.columns.str.startswith('hotelsize')\n",
    "                                       ]\n",
    "\n",
    "EUROSTAT_clean = EUROSTAT_data.drop(columns=columns_to_drop)\n",
    "\n",
    "import re\n",
    "EUROSTAT_clean.rename(columns=lambda x: re.sub(r'ESTAT:|[(]\\d+\\.\\d+[)]', '', x), inplace=True)\n",
    "EUROSTAT_clean.rename(columns=lambda x: re.sub(r'.VALUE', '', x), inplace=True) \n",
    "\n",
    "filtered_columns = EUROSTAT_clean.filter(like='unit')\n",
    "EUROSTAT_clean = EUROSTAT_clean.drop(columns=filtered_columns.columns)\n",
    "EUROSTAT_supervised = EUROSTAT_clean[EUROSTAT_clean['TIME_PERIOD'] >= 2004]\n",
    "EUROSTAT_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661bacde",
   "metadata": {},
   "source": [
    "Now that the dataset is ready, I will preprocess it in the same way as Codebook 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "beea07d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "EUROSTAT_supervised_dummy = pd.get_dummies(EUROSTAT_supervised, drop_first=True) # only 1 cat feature so wont bother defining. whether or not to use `drop_first=True` TBD\n",
    "\n",
    "X = EUROSTAT_supervised_dummy.drop(['RAIL_PA_TOTAL_14'], axis=1)\n",
    "y = EUROSTAT_supervised_dummy['RAIL_PA_TOTAL_14']\n",
    "\n",
    "y = y.dropna() # had issues w missing values in this set\n",
    "X = X.loc[y.index] # matching index to align the two datasets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0) # random state for reproducibility\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train) # only need to appy this to input features to help ML algorithm be more efficient\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "knn_imputer = KNNImputer()\n",
    "X_train_imputed = pd.DataFrame(knn_imputer.fit_transform(X_train), columns=X_train.columns)\n",
    "X_test_imputed = pd.DataFrame(knn_imputer.transform(X_test), columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf8705b",
   "metadata": {},
   "source": [
    "Now I'll fit the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce9ae1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 10, 'n_estimators': 150}\n",
      "RandomForestRegressor(max_depth=10, n_estimators=150, random_state=0)\n",
      "R-squared of the model in training set is: 0.9989447715068346\n",
      "-----Test set statistics-----\n",
      "R-squared of the model in test set is: 0.9928063649785939\n",
      "Root mean squared error of the prediction is: 1850.7931389666421\n",
      "Mean absolute percentage error of the prediction is: 8.500478047669901\n"
     ]
    }
   ],
   "source": [
    "regressor = RandomForestRegressor(random_state = 0)\n",
    "\n",
    "param_grid = {'max_depth': [1, 10, 100, 150], 'n_estimators': [100, 125, 150]} \n",
    "grid_search = GridSearchCV(estimator=regressor, param_grid=param_grid, cv=10, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train_imputed, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "best_model.fit(X_train_imputed, y_train)\n",
    "\n",
    "y_pred_random = best_model.predict(X_test_imputed)\n",
    "\n",
    "print(best_params)\n",
    "print(best_model)\n",
    "\n",
    "print(\"R-squared of the model in training set is: {}\".format(best_model.score(X_train_imputed, y_train)))\n",
    "print(\"-----Test set statistics-----\")\n",
    "print(\"R-squared of the model in test set is: {}\".format(best_model.score(X_test_imputed, y_test)))\n",
    "print(\"Root mean squared error of the prediction is: {}\".format(mse(y_test, y_pred_random)**(1/2)))\n",
    "print(\"Mean absolute percentage error of the prediction is: {}\".format(np.mean(np.abs((y_test - y_pred_random) / y_test)) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730b162b",
   "metadata": {},
   "source": [
    "Interestingly, when run on Mac OS X, the model actually performs better than when run on Windows.\n",
    "\n",
    "**Previous results (from Codebook 2):**  \n",
    "{'max_depth': 100, 'n_estimators': 100}  \n",
    "RandomForestRegressor(max_depth=100, random_state=0)  \n",
    "R-squared of the model in training set is: 0.999042565612404  \n",
    "-----Test set statistics-----    \n",
    "R-squared of the model in test set is: 0.9899003360806337  \n",
    "Root mean squared error of the prediction is: 54063.985747570376  \n",
    "Mean absolute percentage error of the prediction is: 10.826072578458913  \n",
    "\n",
    "**New results:**\n",
    "{'max_depth': 10, 'n_estimators': 150}  \n",
    "RandomForestRegressor(max_depth=10, n_estimators=150, random_state=0)  \n",
    "R-squared of the model in training set is: 0.9989447715068346  \n",
    "-----Test set statistics-----  \n",
    "R-squared of the model in test set is: 0.9928063649785939  \n",
    "Root mean squared error of the prediction is: 1850.7931389666421  \n",
    "Mean absolute percentage error of the prediction is: 8.500478047669901  \n",
    "\n",
    "**In the model run on this Codebook, it has a higher R squared value and a lower RMSE and Mean absolute percentage error, implying it's a better fit and more accurate.**\n",
    "\n",
    "---\n",
    "\n",
    "for the dashboard, I'd like to focus on the feature importance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8c877b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = best_model.feature_importances_\n",
    "features = X_train_imputed.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eaf37e2",
   "metadata": {},
   "source": [
    "I tried the ExplainerDashboard library as suggested in the referenced articles but I got an error saying I had the wrong version, so I changed the version of the library and it still wouldn't work. So I abandoned this approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b310faf0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1384936d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_importance = best_model.feature_importances_ # so I can assess feature importance and plot it\n",
    "features = X_train_imputed.columns\n",
    "\n",
    "feature_display_names = { #to make plot labels easier to interpret\n",
    "    'ILC_PW01': 'TIMSAT',\n",
    "    'ILC_PW01_1': 'LIVENVSAT',\n",
    "    'ILC_PW01_2': 'RELSAT',\n",
    "    'ILC_PW01_5': 'JOBSAT',\n",
    "    'ILC_PW01_6': 'COMSAT',\n",
    "    'ILC_PW01_7': 'ACCSAT',\n",
    "    'ILC_PW01_11': 'GREENSAT',\n",
    "    'ILC_PW01_12': 'LIFESAT',\n",
    "    'ILC_PW01_13': 'MEANLIFE',\n",
    "    'ILC_PW01_15': 'FINSAT'\n",
    "}\n",
    "\n",
    "features_display = [feature_display_names.get(feature, feature) for feature in features] #mapping names to features\n",
    "\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "app.layout = html.Div([\n",
    "    dcc.Tabs([\n",
    "        # Tab 1 over view tab\n",
    "        dcc.Tab(label='Overview', children=[\n",
    "            html.Div([\n",
    "                dcc.Markdown('''\n",
    "                    # Machine learning model for prediction of the amount of passengers travelling on a train in a given year for a given member state\n",
    "                    \n",
    "                    ##### The features in this dataset were named based on their survey codes in the EUROSTAT database.\n",
    "                    * **ACCSAT** | Satisfaction with accommodation\n",
    "                    * **COMSAT** | Satisfaction with commuting time\n",
    "                    * **FINSAT** | Satisfaction with financial situation\n",
    "                    * **GREENSAT** | Satisfaction with recreational and green areas\n",
    "                    * **JOBSAT** | Job satisfaction\n",
    "                    * **LIFESAT** | Overall life satisfaction\n",
    "                    * **LIVENVSAT** | Satisfaction with living environment\n",
    "                    * **MEANLIFE** | Meaning of life\n",
    "                    * **RELSAT** | Satisfaction with personal relationships\n",
    "                    * **TIMSAT** | Satisfaction with time use\n",
    "                    * **TOUR_OCC_NINATS** | Nights spent at hotels and similar accommodation (NACE Rev.2 activity I55.1) by size class\n",
    "                    * **RAIL_TF_PASSMOV** | Passenger train traffic performance by type of train speed\n",
    "                    * **RAIL_PA_TOTAL** | Passengers transported measured in millions of passenger-kilometres\n",
    "                    * **RAIL_AC_CATNMBR** | Railway accidents by type of accident - annual data (2004-2015)\n",
    "                    * **TTR00003** | Total length of railway lines\n",
    "                    \n",
    "                '''),\n",
    "            ])\n",
    "        ]),\n",
    "        \n",
    "        # Tab 2\n",
    "        dcc.Tab(label='Feature Importance', children=[\n",
    "            html.Div([\n",
    "                html.H1(\"Random Forest Feature Importance Dashboard\"),\n",
    "                dcc.Dropdown(\n",
    "                    id='feature-dropdown',\n",
    "                    options=[{'label': feat, 'value': feat} for feat in features_display],\n",
    "                    value=features_display[0],  # Initial feature to display\n",
    "                    multi=False\n",
    "                ),\n",
    "                dcc.Graph(id='feature-importance-plot'),\n",
    "            ])\n",
    "        ]),\n",
    "        \n",
    "        # Tab 3\n",
    "        dcc.Tab(label='Actual vs. Predicted Plots', children=[\n",
    "            html.Div([\n",
    "                html.H1(\"Actual vs. Predicted Plots\"),\n",
    "                dcc.Graph(id='actual-predicted-plot'),\n",
    "            ])\n",
    "        ]),\n",
    "    ])\n",
    "])\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output('feature-importance-plot', 'figure'),\n",
    "    [Input('feature-dropdown', 'value')]\n",
    ")\n",
    "def update_feature_importance_plot(selected_feature):\n",
    "    # Create a DataFrame with feature importance data\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'Feature': features_display,\n",
    "        'Importance': feature_importance\n",
    "    })\n",
    "    feature_importance_df = feature_importance_df[~feature_importance_df['Feature'].str.startswith('geo')]\n",
    "    feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "    fig = px.bar(feature_importance_df, x='Importance', y='Feature', orientation='h',\n",
    "                 title=f'Feature Importance - {selected_feature}')\n",
    "    fig.update_layout(plot_bgcolor='white', paper_bgcolor='white')\n",
    "    fig.update_xaxes(showline=True, linecolor='black', linewidth=1, mirror=True)\n",
    "    fig.update_yaxes(showline=True, linecolor='black', linewidth=1, mirror=True)\n",
    "    \n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output('actual-predicted-plot', 'figure'),\n",
    "    [Input('feature-dropdown', 'value')]\n",
    ")\n",
    "def update_actual_predicted_plot(selected_feature):\n",
    "    fig = px.scatter(x=y_test, y=best_model.predict(X_test_imputed), labels={'x': 'Actual Passenger Count (millions)', 'y': 'Predicted Passenger Count (millions)'},\n",
    "                     title='Actual vs. Predicted Plot')\n",
    "    fig.update_layout(plot_bgcolor='white', paper_bgcolor='white') # minimising data ink\n",
    "    fig.update_xaxes(showline=True, linecolor='black', linewidth=1, mirror=True) #plots weren't easy to read otherwise\n",
    "    fig.update_yaxes(showline=True, linecolor='black', linewidth=1, mirror=True)\n",
    "    fig.update_layout(showlegend=False)\n",
    "\n",
    "    return fig\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70fe8a0",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "As expected, the amount of passengers travelling per km has the highest importance when predicting passenger counts. \n",
    "from actual v predicted plot, it wasn't too far off which is good\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cf3be7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
